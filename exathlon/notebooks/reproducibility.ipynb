{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cface4e2",
   "metadata": {},
   "source": [
    "# Figures 4(a) and 4(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8b9c0",
   "metadata": {},
   "source": [
    "From the `src` directory, run with the default pipeline parameters:\n",
    "\n",
    "```bash\n",
    "> python run_pipeline.py --pipeline-type ad --app-id 0 --model-type ae --scoring-method mse\n",
    "```\n",
    "\n",
    "Then, run the following section of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9875c5f",
   "metadata": {},
   "source": [
    "## Setup and Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c101127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# enable imports directly from the src directory\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.pardir, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "ARGS = {\n",
    "    # data-specific arguments\n",
    "    'data': 'spark',\n",
    "    'app_id': 0,\n",
    "    'trace_types': '.',\n",
    "    'ignored_anomalies': 'none',\n",
    "    \n",
    "    # datasets constitution arguments\n",
    "    'n_starting_removed': 0,\n",
    "    'n_ending_removed': 0,\n",
    "    # optional downsampling to perform on both data and labels to save storage\n",
    "    'pre_sampling_period': '15s',\n",
    "\n",
    "    # features alteration and transformation arguments\n",
    "    'alter_bundles': 'spark_bundles',\n",
    "    'alter_bundle_idx': 0,\n",
    "    # final sampling period to use for data records\n",
    "    'data_sampling_period': '15s',\n",
    "    'data_downsampling_position': 'last',\n",
    "    # final sampling period to use for labels\n",
    "    'labels_sampling_period': '15s',\n",
    "    'transform_chain': 'trace_scaling',\n",
    "    # if a transformation step is repeated, the same arguments are used for all its instances\n",
    "    'head_size': 240,\n",
    "    'online_window_type': 'expanding',\n",
    "    # if not -1, weight of a regular pretraining of the scaler in\n",
    "    # the convex combination with its head/head-online training\n",
    "    'regular_pretraining_weight': -1,\n",
    "    'scaling_method': 'std',\n",
    "    # only relevant for \"regular\" scaling\n",
    "    'reg_scaler_training': 'all.training',\n",
    "    'minmax_range': [0, 1],\n",
    "    'pca_n_components': 13,\n",
    "    'pca_kernel': 'linear',\n",
    "    'pca_training': 'all.training',\n",
    "    'fa_n_components': 13,\n",
    "    'fa_training': 'all.training',\n",
    "\n",
    "    # normality modeling arguments\n",
    "    'modeling_n_periods': -1,\n",
    "    'modeling_data_prop': 1.0,\n",
    "    'modeling_data_seed': 0,\n",
    "    'modeling_split': 'stratified.split',\n",
    "    'modeling_split_seed': 21,\n",
    "    'n_period_strata': 3,\n",
    "    'modeling_val_prop': 0.15,\n",
    "    'modeling_test_prop': 0.15,\n",
    "    'model_type': 'ae',\n",
    "    # FORECASTING MODELS #\n",
    "    'n_back': 40,\n",
    "    'n_forward': 1,\n",
    "    # RNN\n",
    "    'rnn_unit_type': 'lstm',\n",
    "    'rnn_n_hidden_neurons': [144, 40],\n",
    "    'rnn_dropout': 0.0,\n",
    "    'rnn_rec_dropout': 0.0,\n",
    "    'rnn_optimizer': 'adam',\n",
    "    'rnn_learning_rate': 7.869 * (10 ** -4),\n",
    "    'rnn_n_epochs': 200,\n",
    "    'rnn_batch_size': 32,\n",
    "    # RECONSTRUCTION MODELS #\n",
    "    'window_size': 40,\n",
    "    'window_step': 1,\n",
    "    # autoencoder\n",
    "    'ae_latent_dim': 32,\n",
    "    'ae_type': 'dense',\n",
    "    'ae_enc_n_hidden_neurons': [200],\n",
    "    'ae_dec_last_activation': 'linear',\n",
    "    'ae_dropout': 0.0,\n",
    "    'ae_dense_layers_activation': 'relu',\n",
    "    'ae_rec_unit_type': 'lstm',\n",
    "    'ae_rec_dropout': 0.0,\n",
    "    'ae_loss': 'mse',\n",
    "    'ae_optimizer': 'adam',\n",
    "    'ae_learning_rate': 3.602 * (10 ** -4),\n",
    "    'ae_n_epochs': 200,\n",
    "    'ae_batch_size': 32,\n",
    "    # BiGAN\n",
    "    'bigan_latent_dim': 32,\n",
    "    'bigan_enc_type': 'rec',\n",
    "    'bigan_enc_arch_idx': -1,\n",
    "    'bigan_enc_rec_n_hidden_neurons': [100],\n",
    "    'bigan_enc_rec_unit_type': 'lstm',\n",
    "    'bigan_enc_conv_n_filters': 32,\n",
    "    'bigan_enc_dropout': 0.0,\n",
    "    'bigan_enc_rec_dropout': 0.0,\n",
    "    'bigan_gen_type': 'rec',\n",
    "    'bigan_gen_last_activation': 'linear',\n",
    "    'bigan_gen_arch_idx': -1,\n",
    "    'bigan_gen_rec_n_hidden_neurons': [100],\n",
    "    'bigan_gen_rec_unit_type': 'lstm',\n",
    "    'bigan_gen_conv_n_filters': 64,\n",
    "    'bigan_gen_dropout': 0.0,\n",
    "    'bigan_gen_rec_dropout': 0.0,\n",
    "    'bigan_dis_type': 'conv',\n",
    "    'bigan_dis_arch_idx': 0,\n",
    "    'bigan_dis_x_rec_n_hidden_neurons': [30, 10],\n",
    "    'bigan_dis_x_rec_unit_type': 'lstm',\n",
    "    'bigan_dis_x_conv_n_filters': 32,\n",
    "    'bigan_dis_x_dropout': 0.0,\n",
    "    'bigan_dis_x_rec_dropout': 0.0,\n",
    "    'bigan_dis_z_n_hidden_neurons': [32, 10],\n",
    "    'bigan_dis_z_dropout': 0.0,\n",
    "    'bigan_dis_threshold': 0.0,\n",
    "    'bigan_dis_optimizer': 'adam',\n",
    "    'bigan_enc_gen_optimizer': 'adam',\n",
    "    'bigan_dis_learning_rate': 0.0004,\n",
    "    'bigan_enc_gen_learning_rate': 0.0001,\n",
    "    'bigan_n_epochs': 200,\n",
    "    'bigan_batch_size': 32,\n",
    "\n",
    "    # outlier score assignment arguments\n",
    "    'scoring_method': 'mse',\n",
    "    'mse_weight': 0.5,\n",
    "\n",
    "    # supervised evaluation for assessing scoring performance\n",
    "    'evaluation_type': 'ad2',\n",
    "    'recall_alpha': 0.0,\n",
    "    'recall_omega': 'default',\n",
    "    'recall_delta': 'flat',\n",
    "    'recall_gamma': 'dup',\n",
    "    'precision_omega': 'default',\n",
    "    'precision_delta': 'flat',\n",
    "    'precision_gamma': 'dup',\n",
    "    'f_score_beta': 1.0,\n",
    "\n",
    "    # outlier score threshold selection arguments\n",
    "    'thresholding_method': ['std', 'mad', 'iqr'],\n",
    "    'thresholding_factor': [1.5, 2.0, 2.5, 3.0],\n",
    "    'n_iterations': [1, 2],\n",
    "    'removal_factor': [1.0],\n",
    "\n",
    "    # explanation discovery arguments\n",
    "    'explanation_method': 'exstream',\n",
    "    'explained_predictions': 'ground.truth',\n",
    "    # ED evaluation parameters\n",
    "    'ed_eval_min_anomaly_length': 1,\n",
    "    'ed1_consistency_n_disturbances': 5,\n",
    "    # model-free evaluation\n",
    "    'mf_eval_min_normal_length': 1,\n",
    "    'mf_ed1_consistency_sampled_prop': 0.8,\n",
    "    'mf_ed1_accuracy_n_splits': 5,\n",
    "    'mf_ed1_accuracy_test_prop': 0.2,\n",
    "    # model-dependent evaluation\n",
    "    'md_eval_small_anomalies_expansion': 'before',\n",
    "    'md_eval_large_anomalies_coverage': 'all',\n",
    "    # EXstream\n",
    "    'exstream_fp_scaled_std_threshold': 1.64,\n",
    "    # MacroBase\n",
    "    'macrobase_n_bins': 10,\n",
    "    'macrobase_min_support': 0.4,\n",
    "    'macrobase_min_risk_ratio': 1.5,\n",
    "    # LIME\n",
    "    'lime_n_features': 5,\n",
    "\n",
    "    # pipeline execution shortcut arguments\n",
    "    'pipeline_type': 'ad'\n",
    "}\n",
    "args = argparse.Namespace(**ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12bc3a9",
   "metadata": {},
   "source": [
    "## Figure 4(a) - Trace-wise Separation for T2 Trace of Application 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "from utils.common import PIPELINE_TEST_NAME, get_output_path, get_modeling_task_and_classes\n",
    "from data.helpers import load_datasets_data\n",
    "\n",
    "# set input and output paths\n",
    "DATA_INFO_PATH = get_output_path(args, 'make_datasets')\n",
    "DATA_INPUT_PATH = get_output_path(args, 'build_features', 'data')\n",
    "MODEL_INPUT_PATH = get_output_path(args, 'train_model')\n",
    "OUTPUT_PATH = get_output_path(args, 'train_detector', 'model')\n",
    "\n",
    "# load test data\n",
    "data = load_datasets_data(DATA_INPUT_PATH, DATA_INFO_PATH, [PIPELINE_TEST_NAME])\n",
    "\n",
    "# initialize relevant scorer based on command-line arguments\n",
    "task_type, model_classes = get_modeling_task_and_classes(args)\n",
    "a_t = 'the type of task must be either `forecasting` or `reconstruction`'\n",
    "assert task_type in ['forecasting', 'reconstruction'], a_t\n",
    "scoring_classes = importlib.import_module(f'scoring.{task_type}.{task_type}_scorers').scoring_classes\n",
    "if args.model_type == 'naive.forecasting':\n",
    "    model = model_classes[args.model_type](args, '')\n",
    "else:\n",
    "    model = model_classes[args.model_type].from_file(args, MODEL_INPUT_PATH)\n",
    "scorer = scoring_classes[args.scoring_method](args, model, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# derive outlier scores for T2 trace of application 2\n",
    "trace_name = '2_2_200000_69'\n",
    "\n",
    "trace_idx = [i for i, t in enumerate(data['test_info']) if t[0] == trace_name][0]\n",
    "trace_data, trace_labels = np.array([data['test'][trace_idx]]), np.array([data['y_test'][trace_idx]])\n",
    "trace_scores = scorer.score(trace_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ecc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.spark import ANOMALY_TYPES\n",
    "from visualization.periods.array import plot_scores_distributions\n",
    "from visualization.helpers.spark import METRICS_COLORS\n",
    "    \n",
    "# plot outlier scores distribution\n",
    "plot_scores_distributions(\n",
    "    trace_scores, trace_labels,\n",
    "    fig_title=f'Scores Distributions for Trace \"{trace_name}\"',\n",
    "    type_colors=METRICS_COLORS,\n",
    "    anomaly_types=ANOMALY_TYPES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f32a6",
   "metadata": {},
   "source": [
    "## Figure 4(d) - Outlier Scores of Modeling Test Samples with \"Best\" Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67523460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from utils.common import PIPELINE_TRAIN_NAME, MODELING_TEST_NAME, get_best_thresholding_args\n",
    "from data.helpers import load_mixed_formats\n",
    "from modeling.data_splitters import get_splitter_classes\n",
    "from modeling.forecasting.helpers import get_trimmed_periods\n",
    "\n",
    "# load test samples of the modeling set\n",
    "if task_type == 'forecasting':\n",
    "    data[f'y_{PIPELINE_TEST_NAME}'] = get_trimmed_periods(data[f'y_{PIPELINE_TEST_NAME}'], args.n_back)\n",
    "    kwargs = {'n_back': args.n_back, 'n_forward': args.n_forward}\n",
    "else:\n",
    "    kwargs = {'window_size': args.window_size, 'window_step': args.window_step}\n",
    "\n",
    "print('loading training periods and information...', end=' ', flush=True)\n",
    "modeling_files = load_mixed_formats(\n",
    "    [DATA_INPUT_PATH, DATA_INFO_PATH],\n",
    "    [PIPELINE_TRAIN_NAME, f'{PIPELINE_TRAIN_NAME}_info'],\n",
    "    ['numpy', 'pickle']\n",
    ")\n",
    "print('done.')\n",
    "print('recovering modeling test samples...', end=' ', flush=True)\n",
    "data_splitter = get_splitter_classes()[args.modeling_split](args)\n",
    "data = data_splitter.get_modeling_split(\n",
    "    modeling_files[PIPELINE_TRAIN_NAME], modeling_files[f'{PIPELINE_TRAIN_NAME}_info'], **kwargs\n",
    ")\n",
    "modeling_test_data = {\n",
    "    k.replace(f'_{MODELING_TEST_NAME}', ''): v for k, v in data.items() if MODELING_TEST_NAME in k\n",
    "}\n",
    "print('done.')\n",
    "\n",
    "# load \"best\" outlier score threshold value\n",
    "best_threshold = pickle.load(open(\n",
    "    os.path.join(get_output_path(get_best_thresholding_args(args), 'train_detector'), 'threshold.pkl'), 'rb'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b668f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format modeling test samples according to the type of method\n",
    "if 'y' in modeling_test_data:\n",
    "    if len(modeling_test_data['y'].shape) == 2:\n",
    "        n_samples, n_features = modeling_test_data['y'].shape\n",
    "        modeling_test_data['y'] = modeling_test_data['y'].reshape((n_samples, 1, n_features))\n",
    "    modeling_test_samples = np.array([\n",
    "        np.concatenate([X, y]) for X, y in zip(modeling_test_data['X'], modeling_test_data['y'])\n",
    "    ])\n",
    "else:\n",
    "    modeling_test_samples = modeling_test_data['X']\n",
    "                    \n",
    "# derive modeling test outlier scores\n",
    "modeling_test_scores = scorer.score_windows(modeling_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot outlier scores distribution of modeling test samples, with highlighted \"best\" threshold value\n",
    "metrics_colors = METRICS_COLORS.copy()\n",
    "metrics_colors['normal'] = 'deepskyblue'\n",
    "\n",
    "plot_scores_distributions(\n",
    "    np.array([np.array(modeling_test_scores)]), np.array([np.zeros(shape=(len(modeling_test_scores),))]),\n",
    "    fig_title=f'Scores Distributions of the Modeling Test Samples',\n",
    "    threshold=best_threshold,\n",
    "    type_colors=metrics_colors,\n",
    "    anomaly_types=ANOMALY_TYPES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba9316",
   "metadata": {},
   "source": [
    "# Experiment 3 (Figure 5, Increasing Training Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa07a4b",
   "metadata": {},
   "source": [
    "From the `src` directory, run with the default pipeline parameters (in particular, with the default value of _\"--app-id\"_ being 0 in *utils.spark.py*, for \"all applications\"):\n",
    "\n",
    "```bash\n",
    "> python data/make_datasets.py\n",
    "> python features/build_features.py\n",
    "\n",
    "> cd experiments\n",
    "\n",
    "> experiment_3.sh rnn 0 0\n",
    "> experiment_3.sh rnn 1 1\n",
    "> experiment_3.sh rnn 2 2\n",
    "> experiment_3.sh rnn 3 3\n",
    "> experiment_3.sh rnn 4 4\n",
    "\n",
    "> experiment_3.sh ae 0 0\n",
    "> experiment_3.sh ae 1 1\n",
    "> experiment_3.sh ae 2 2\n",
    "> experiment_3.sh ae 3 3\n",
    "> experiment_3.sh ae 4 4\n",
    "\n",
    "> experiment_3.sh bigan 0 0\n",
    "> experiment_3.sh bigan 1 1\n",
    "> experiment_3.sh bigan 2 2\n",
    "> experiment_3.sh bigan 3 3\n",
    "> experiment_3.sh bigan 4 4\n",
    "```\n",
    "\n",
    "Then, run the following section of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acae406",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# enable imports directly from the src directory\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.pardir, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "ARGS = {\n",
    "    # data-specific arguments\n",
    "    'data': 'spark',\n",
    "    'app_id': 0,\n",
    "    'trace_types': '.',\n",
    "    'ignored_anomalies': 'none',\n",
    "    \n",
    "    # datasets constitution arguments\n",
    "    'n_starting_removed': 0,\n",
    "    'n_ending_removed': 0,\n",
    "    # optional downsampling to perform on both data and labels to save storage\n",
    "    'pre_sampling_period': '15s',\n",
    "\n",
    "    # features alteration and transformation arguments\n",
    "    'alter_bundles': 'spark_bundles',\n",
    "    'alter_bundle_idx': 0,\n",
    "    # final sampling period to use for data records\n",
    "    'data_sampling_period': '15s',\n",
    "    'data_downsampling_position': 'last',\n",
    "    # final sampling period to use for labels\n",
    "    'labels_sampling_period': '15s',\n",
    "    'transform_chain': 'trace_scaling',\n",
    "    # if a transformation step is repeated, the same arguments are used for all its instances\n",
    "    'head_size': 240,\n",
    "    'online_window_type': 'expanding',\n",
    "    # if not -1, weight of a regular pretraining of the scaler in\n",
    "    # the convex combination with its head/head-online training\n",
    "    'regular_pretraining_weight': -1,\n",
    "    'scaling_method': 'std',\n",
    "    # only relevant for \"regular\" scaling\n",
    "    'reg_scaler_training': 'all.training',\n",
    "    'minmax_range': [0, 1],\n",
    "    'pca_n_components': 13,\n",
    "    'pca_kernel': 'linear',\n",
    "    'pca_training': 'all.training',\n",
    "    'fa_n_components': 13,\n",
    "    'fa_training': 'all.training',\n",
    "\n",
    "    # normality modeling arguments\n",
    "    'modeling_n_periods': -1,\n",
    "    'modeling_data_prop': 1.0,\n",
    "    'modeling_data_seed': 0,\n",
    "    'modeling_split': 'stratified.split',\n",
    "    'modeling_split_seed': 21,\n",
    "    'n_period_strata': 3,\n",
    "    'modeling_val_prop': 0.15,\n",
    "    'modeling_test_prop': 0.15,\n",
    "    'model_type': 'ae',\n",
    "    # FORECASTING MODELS #\n",
    "    'n_back': 40,\n",
    "    'n_forward': 1,\n",
    "    # RNN\n",
    "    'rnn_unit_type': 'lstm',\n",
    "    'rnn_n_hidden_neurons': [144, 40],\n",
    "    'rnn_dropout': 0.0,\n",
    "    'rnn_rec_dropout': 0.0,\n",
    "    'rnn_optimizer': 'adam',\n",
    "    'rnn_learning_rate': 7.869 * (10 ** -4),\n",
    "    'rnn_n_epochs': 200,\n",
    "    'rnn_batch_size': 32,\n",
    "    # RECONSTRUCTION MODELS #\n",
    "    'window_size': 40,\n",
    "    'window_step': 1,\n",
    "    # autoencoder\n",
    "    'ae_latent_dim': 32,\n",
    "    'ae_type': 'dense',\n",
    "    'ae_enc_n_hidden_neurons': [200],\n",
    "    'ae_dec_last_activation': 'linear',\n",
    "    'ae_dropout': 0.0,\n",
    "    'ae_dense_layers_activation': 'relu',\n",
    "    'ae_rec_unit_type': 'lstm',\n",
    "    'ae_rec_dropout': 0.0,\n",
    "    'ae_loss': 'mse',\n",
    "    'ae_optimizer': 'adam',\n",
    "    'ae_learning_rate': 3.602 * (10 ** -4),\n",
    "    'ae_n_epochs': 200,\n",
    "    'ae_batch_size': 32,\n",
    "    # BiGAN\n",
    "    'bigan_latent_dim': 32,\n",
    "    'bigan_enc_type': 'rec',\n",
    "    'bigan_enc_arch_idx': -1,\n",
    "    'bigan_enc_rec_n_hidden_neurons': [100],\n",
    "    'bigan_enc_rec_unit_type': 'lstm',\n",
    "    'bigan_enc_conv_n_filters': 32,\n",
    "    'bigan_enc_dropout': 0.0,\n",
    "    'bigan_enc_rec_dropout': 0.0,\n",
    "    'bigan_gen_type': 'rec',\n",
    "    'bigan_gen_last_activation': 'linear',\n",
    "    'bigan_gen_arch_idx': -1,\n",
    "    'bigan_gen_rec_n_hidden_neurons': [100],\n",
    "    'bigan_gen_rec_unit_type': 'lstm',\n",
    "    'bigan_gen_conv_n_filters': 64,\n",
    "    'bigan_gen_dropout': 0.0,\n",
    "    'bigan_gen_rec_dropout': 0.0,\n",
    "    'bigan_dis_type': 'conv',\n",
    "    'bigan_dis_arch_idx': 0,\n",
    "    'bigan_dis_x_rec_n_hidden_neurons': [30, 10],\n",
    "    'bigan_dis_x_rec_unit_type': 'lstm',\n",
    "    'bigan_dis_x_conv_n_filters': 32,\n",
    "    'bigan_dis_x_dropout': 0.0,\n",
    "    'bigan_dis_x_rec_dropout': 0.0,\n",
    "    'bigan_dis_z_n_hidden_neurons': [32, 10],\n",
    "    'bigan_dis_z_dropout': 0.0,\n",
    "    'bigan_dis_threshold': 0.0,\n",
    "    'bigan_dis_optimizer': 'adam',\n",
    "    'bigan_enc_gen_optimizer': 'adam',\n",
    "    'bigan_dis_learning_rate': 0.0004,\n",
    "    'bigan_enc_gen_learning_rate': 0.0001,\n",
    "    'bigan_n_epochs': 200,\n",
    "    'bigan_batch_size': 32,\n",
    "\n",
    "    # outlier score assignment arguments\n",
    "    'scoring_method': 'mse',\n",
    "    'mse_weight': 0.5,\n",
    "\n",
    "    # supervised evaluation for assessing scoring performance\n",
    "    'evaluation_type': 'ad2',\n",
    "    'recall_alpha': 0.0,\n",
    "    'recall_omega': 'default',\n",
    "    'recall_delta': 'flat',\n",
    "    'recall_gamma': 'dup',\n",
    "    'precision_omega': 'default',\n",
    "    'precision_delta': 'flat',\n",
    "    'precision_gamma': 'dup',\n",
    "    'f_score_beta': 1.0,\n",
    "\n",
    "    # outlier score threshold selection arguments\n",
    "    'thresholding_method': ['std', 'mad', 'iqr'],\n",
    "    'thresholding_factor': [1.5, 2.0, 2.5, 3.0],\n",
    "    'n_iterations': [1, 2],\n",
    "    'removal_factor': [1.0],\n",
    "\n",
    "    # explanation discovery arguments\n",
    "    'explanation_method': 'exstream',\n",
    "    'explained_predictions': 'ground.truth',\n",
    "    # ED evaluation parameters\n",
    "    'ed_eval_min_anomaly_length': 1,\n",
    "    'ed1_consistency_n_disturbances': 5,\n",
    "    # model-free evaluation\n",
    "    'mf_eval_min_normal_length': 1,\n",
    "    'mf_ed1_consistency_sampled_prop': 0.8,\n",
    "    'mf_ed1_accuracy_n_splits': 5,\n",
    "    'mf_ed1_accuracy_test_prop': 0.2,\n",
    "    # model-dependent evaluation\n",
    "    'md_eval_small_anomalies_expansion': 'before',\n",
    "    'md_eval_large_anomalies_coverage': 'all',\n",
    "    # EXstream\n",
    "    'exstream_fp_scaled_std_threshold': 1.64,\n",
    "    # MacroBase\n",
    "    'macrobase_n_bins': 10,\n",
    "    'macrobase_min_support': 0.4,\n",
    "    'macrobase_min_risk_ratio': 1.5,\n",
    "    # LIME\n",
    "    'lime_n_features': 5,\n",
    "\n",
    "    # pipeline execution shortcut arguments\n",
    "    'pipeline_type': 'ad'\n",
    "}\n",
    "args = argparse.Namespace(**ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a196007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from utils.common import get_args_string, get_output_path\n",
    "from data.helpers import load_files\n",
    "\n",
    "\n",
    "def get_data_prop_and_performance(args, n_periods, data_seed, split_seed, agg='median', granularity='app_avg'):\n",
    "    \"\"\"Returns the proportion of normal data used by the method along with its median/best test F1-score.\n",
    "        \n",
    "    The test F1-score is returned for the provided data granularity, either as the median or \"best\"\n",
    "    score across the evaluated thresholding parameters.\n",
    "    \n",
    "    Args:\n",
    "        args (argparse.Namespace): parsed command-line arguments.\n",
    "        n_periods (int): number of periods used by the method for modeling the normal behavior. \n",
    "        data_seed (int): modeling data selection random seed. \n",
    "        split_seed (int): modeling data splitting random seed. \n",
    "        agg (str): performance aggregation to perform across the test F1-scores (either \"best\" or \"median\").\n",
    "        granularity (str): evaluation granularity (index of the \"granularity\" column of the evaluation spreadsheet).\n",
    "\n",
    "    Returns:\n",
    "        float, float: proportion of normal data used by the method along with its median/best test F1-score.\n",
    "    \"\"\"\n",
    "    assert agg in ['best', 'median'], 'the provided aggregation method must be either \"best\" or \"median\"'\n",
    "    args_dict, fn = vars(args), 'selected_periods_info'\n",
    "    keys = ['modeling_n_periods', 'modeling_data_seed', 'modeling_split_seed']\n",
    "    values = [n_periods, data_seed, split_seed]\n",
    "    for k, v in zip(keys, values):\n",
    "        args_dict[k] = v\n",
    "    args_copy = argparse.Namespace(**args_dict)\n",
    "    data_prop = load_files(get_output_path(args_copy, 'train_model'), [fn], 'json')[fn]['data_prop']\n",
    "    evaluation_fn = f'{get_args_string(args, \"ad_evaluation\")}_detection_comparison.csv'\n",
    "    evaluation_path = os.path.join(get_output_path(args_copy, 'train_scorer'), evaluation_fn)\n",
    "    evaluation_df = pd.read_csv(evaluation_path, index_col=[0, 1])\n",
    "    if agg == 'median': \n",
    "        median_block = evaluation_df.groupby(evaluation_df.index.get_level_values('granularity')).median()\n",
    "        filtered_block = median_block.loc[median_block.index == granularity]\n",
    "        f_score = filtered_block['TEST_GLOBAL_F1.0_SCORE'].iloc[0]\n",
    "    else:\n",
    "        f_score = eval_df.loc[\n",
    "            evaluation_df.index.get_level_values('granularity') == granularity\n",
    "        ].sort_values('TEST_GLOBAL_F1.0_SCORE', ascending=False).iloc[0]['TEST_GLOBAL_F1.0_SCORE']        \n",
    "    return data_prop, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c606b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of undisturbed (i.e., normal) traces\n",
    "TOT_N_TRACES = 52\n",
    "\n",
    "# performance curves grouped by AD method and random seed\n",
    "seed_curves = dict()\n",
    "for model_type, scoring_method in zip(['ae', 'rnn', 'bigan'], ['mse', 're', 'mse.ft']):\n",
    "    args_copy = argparse.Namespace(**vars(args))\n",
    "    args_copy.model_type, args_copy.scoring_method = model_type, scoring_method\n",
    "    # performance curves for the AD method\n",
    "    seed_curves[model_type] = dict()\n",
    "    for random_seed in range(5):\n",
    "        # performance curve for the random seed (`x` is proportion of normal data, `y` is performance)\n",
    "        seed_curve = {'x': [], 'y': []}\n",
    "        for n_periods in range(1, TOT_N_TRACES + 1):\n",
    "            # ignore the step if data is not available\n",
    "            try: \n",
    "                x, y = get_data_prop_and_performance(args_copy, n_periods, random_seed, random_seed)\n",
    "                for k, v in zip(['x', 'y'], [x, y]): \n",
    "                    seed_curve[k].append(v)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        # only add seed keys for which data could be loaded\n",
    "        if not any([len(seed_curve[k]) == 0 for k in ['x', 'y']]): \n",
    "            seed_curves[model_type][random_seed] = seed_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52cf46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "def get_curve_interpolation(x, y, n_points=300):\n",
    "    \"\"\"Returns interpolated (x, y) pairs as evenly-spaced points between the min and max x values.\"\"\"\n",
    "    new_x = np.linspace(min(x), max(x), num=n_points)\n",
    "    # type BSpline\n",
    "    spl = make_interp_spline(np.sort(x), y, k=1)  \n",
    "    return new_x, spl(new_x)\n",
    "\n",
    "def plot_average_curve(ax, curves_dict, curve_label, curve_color, n_points=300):\n",
    "    \"\"\"From the provided curves dictionary, plots the average curve across keys, highlighting the std.\n",
    "    \n",
    "    The x values of the curves do not need to be the same, as long as they share the same minimum and\n",
    "    maximum values, since interpolation will be used to make each curve have `n_points` points.\n",
    "    \n",
    "    Args:\n",
    "        ax (AxesSubplot): plt.axis on which to plot the average curve.\n",
    "        curves_dict (dict): curves dictionary, with each curve as a dict with keys `x` and `y`.\n",
    "        curve_label (str): label to use for the average curve in the legend.\n",
    "        curve_label (int|str): color of the average curve.\n",
    "        n_points (int): number of points to show for the curves after interpolation. \n",
    "    \"\"\"\n",
    "    # get interpolated curves from the provided curves dictionary\n",
    "    interp_curves = dict()\n",
    "    for k in curves_dict:\n",
    "        x, y = get_curve_interpolation(curves_dict[k]['x'], curves_dict[k]['y'], n_points)\n",
    "        interp_curves[k] = {'x': x, 'y': y}\n",
    "    \n",
    "    # get mean and standard deviation for the curves\n",
    "    interp_mean = {'x': interp_curves[list(interp_curves.keys())[0]]['x']}\n",
    "    interp_mean['y'] = np.mean([interp_curves[k]['y'] for k in interp_curves], axis=0)\n",
    "    interp_std = np.std([interp_curves[k]['y'] for k in interp_curves], axis=0)\n",
    "    \n",
    "    # plot the average curve, highlighting the standard deviation\n",
    "    ax.plot(interp_mean['x'], interp_mean['y'], label=curve_label, c=curve_color)\n",
    "    ax.fill_between(interp_mean['x'], interp_mean['y'] - interp_std, interp_mean['y'] + interp_std, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot average curve for each AD method\n",
    "labels_dict = {'ae': 'Autoencoder', 'rnn': 'LSTM', 'bigan': 'BiGAN'}\n",
    "colors_dict = {'ae': 'blue', 'rnn': 'red', 'bigan': 'green'}\n",
    "fontsizes = {\n",
    "    'labels': 20,\n",
    "    'ticks': 18,\n",
    "    'legend': 18\n",
    "}\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 3))\n",
    "for model_type in seed_curves:\n",
    "    plot_average_curve(ax, seed_curves[model_type], labels_dict[model_type], colors_dict[model_type])\n",
    "\n",
    "# set figure options\n",
    "ax.legend(prop={'size': fontsizes['legend']}, frameon=False, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.set_xlabel('Proportion of Normal Data', size=fontsizes['labels'])\n",
    "ax.set_ylabel('Median F1-Score', size=fontsizes['labels'])\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsizes['ticks'])\n",
    "ax.tick_params(axis='both', which='minor', labelsize=fontsizes['ticks'])\n",
    "ax.grid(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
